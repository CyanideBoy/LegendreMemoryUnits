{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "psMNIST_exp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXemUJw6bfZe"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0Xm-9oOaucQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4faa192c-f681-44c6-acce-8544d1147e91"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1M0Z3Xd6oQD"
      },
      "source": [
        "train_batch = 60000\n",
        "test_batch = 10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UB6uC1-gnTB3",
        "outputId": "356a7c3e-481a-4c9e-8773-dd826607fe27"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24-M4sImdaOS"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.1307,), (0.3081,)),\n",
        "                               torchvision.transforms.Lambda(lambda x: x.view(-1,1))\n",
        "                             ])),\n",
        "  batch_size=train_batch, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.1307,), (0.3081,)),\n",
        "                               torchvision.transforms.Lambda(lambda x: x.view(-1,1))\n",
        "                             ])),\n",
        "  batch_size=test_batch, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwbEU6puRsRc"
      },
      "source": [
        "# **LMU, BMU, LLMU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLnz6c25Rxti",
        "outputId": "84285025-afd6-4109-d140-4de004934ac3"
      },
      "source": [
        "!pip install nengolib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nengolib in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from nengolib) (1.4.1)\n",
            "Requirement already satisfied: nengo<3.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from nengolib) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.7/dist-packages (from nengolib) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8DW5xELR-an"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from nengolib.signal import Identity,cont2discrete\n",
        "from nengolib.synapses import LegendreDelay\n",
        "import numpy as np\n",
        "from scipy.special import comb\n",
        "\n",
        "\n",
        "class LMU(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, memory_size, theta, matrix_type='pl',discretizer = 'zoh',nonlinearity='sigmoid', A_learnable = False, B_learnable = False):\n",
        "        super(LMU, self).__init__()\n",
        "\n",
        "        ### SIZE\n",
        "        self.k = input_size\n",
        "        self.n = hidden_size\n",
        "        self.d = memory_size\n",
        "\n",
        "        ### PARAMETERS\n",
        "        self.Wx = nn.Parameter(torch.Tensor(self.n,self.k))\n",
        "        self.Wh = nn.Parameter(torch.Tensor(self.n,self.n))\n",
        "        self.Wm = nn.Parameter(torch.Tensor(self.n,self.d))\n",
        "        self.ex = nn.Parameter(torch.Tensor(1,self.k))\n",
        "        self.eh = nn.Parameter(torch.Tensor(1,self.n))\n",
        "        self.em = nn.Parameter(torch.Tensor(1,self.d))\n",
        "\n",
        "        ### A,B MATRIX ----- FIX??\n",
        "\n",
        "        if matrix_type=='pl':   #For Legendre Memory Unit\n",
        "            order=self.d\n",
        "            Q = np.arange(order, dtype=np.float64)\n",
        "            R = (2 * Q + 1)[:, None] / theta\n",
        "            j, i = np.meshgrid(Q, Q)\n",
        "            A = np.where(i < j, -1, (-1.0) ** (i - j + 1)) * R\n",
        "            B = (-1.0) ** Q[:, None] * R\n",
        "            C = np.ones((1, order))\n",
        "            D = np.zeros((1,))\n",
        "            self._ss = cont2discrete((A, B, C, D), dt=0.01, method=discretizer)\n",
        "            self._A = self._ss.A\n",
        "            self._B = self._ss.B\n",
        "        elif matrix_type=='p':  #For Pade Memory Unit\n",
        "            order=self.d\n",
        "            Q=np.arange(order,dtype=np.float64)\n",
        "            V=(order+Q+1)*(order-Q)/(Q+1)/theta\n",
        "            A=np.zeros([order,order],dtype=np.float64)\n",
        "            B=np.zeros([order,1],dtype=np.float64)\n",
        "            A[0,:]=-V[0]\n",
        "            A[1:order,0:order-1]=np.diag(V[1:order])\n",
        "            B[0]=V[0]\n",
        "            C = np.ones((1, order))\n",
        "            D = np.zeros((1,))\n",
        "            self._ss = cont2discrete((A, B, C, D), dt=0.01, method=discretizer)\n",
        "            self._A = self._ss.A\n",
        "            self._B = self._ss.B\n",
        "        elif matrix_type=='pb':  #For Bernstein Memory Unit\n",
        "            order=self.d\n",
        "            Q = np.arange(order, dtype=np.float64)\n",
        "            R = (2 * Q + 1)[:, None] / theta\n",
        "            j, i = np.meshgrid(Q, Q)\n",
        "            A_leg = np.where(i < j, -1, (-1.0) ** (i - j + 1)) * R\n",
        "            B_leg = (-1.0) ** Q[:, None] * R\n",
        "            C = np.ones((1, order))\n",
        "            D = np.zeros((1,))\n",
        "            M=np.zeros([order,order],dtype=np.float64)\n",
        "            M_inv=np.zeros([order,order],dtype=np.float64)\n",
        "            n=order-1 #degree of polynomial\n",
        "            for j in range(0,n+1):\n",
        "              for k in range(0,n+1):\n",
        "                ll=max(0,j+k-n)\n",
        "                ul=min(j,k)+1\n",
        "                sum=0.0\n",
        "                for i in range(ll,ul):\n",
        "                  sum=sum+((-1.0)**(k+i))*(comb(k,i)**2)*comb(n-k,j-i)\n",
        "                M[j,k]=sum/comb(n,j)\n",
        "\n",
        "                sum=0.0\n",
        "                for i in range(0,j+1):\n",
        "                  sum=sum+(-1.0)**(j+i)*comb(j,i)**2/comb(n+j,k+i)\n",
        "                M_inv[j,k]=(2*j+1)/(n+j+1)*comb(n,k)*sum\n",
        "\n",
        "            M=10*np.tanh(M/10)\n",
        "            M_inv=10*np.tanh(M_inv/10)\n",
        "\n",
        "            A_1=np.matmul(M,A_leg)\n",
        "            A=np.matmul(A_1,M_inv)\n",
        "            B=np.matmul(M,B_leg)\n",
        "\n",
        "            self._ss = cont2discrete((A, B, C, D), dt=0.01, method=discretizer)\n",
        "            self._A = self._ss.A\n",
        "            self._B = self._ss.B\n",
        "\n",
        "        ### NON-LINEARITY\n",
        "        self.nl = nonlinearity\n",
        "        if self.nl == 'sigmoid':\n",
        "            self.act = nn.Sigmoid()\n",
        "        elif self.nl == 'tanh':\n",
        "            self.act = nn.Tanh()\n",
        "        else:\n",
        "            self.act = nn.ReLU()\n",
        "\n",
        "        ### INITIALIZATION\n",
        "        torch.nn.init.xavier_normal_(self.Wm)    ##### FIGURE THIS OUT!!\n",
        "        torch.nn.init.xavier_normal_(self.Wx)\n",
        "        torch.nn.init.xavier_normal_(self.Wh)\n",
        "        torch.nn.init.zeros_(self.em)\n",
        "        torch.nn.init.uniform_(self.ex, -np.sqrt(3/self.d), np.sqrt(3/self.d))\n",
        "        torch.nn.init.uniform_(self.eh, -np.sqrt(3/self.d), np.sqrt(3/self.d))\n",
        "\n",
        "\n",
        "        #### TRIAL\n",
        "        self.register_buffer('AT', torch.Tensor(self._A))\n",
        "        self.register_buffer('BT', torch.Tensor(self._B))\n",
        "        if A_learnable:\n",
        "            self.AT = nn.Parameter(self.AT)\n",
        "        if B_learnable:\n",
        "            self.BT = nn.Parameter(self.BT)\n",
        "\n",
        "\n",
        "    def forward(self,x,hm):\n",
        "\n",
        "        h,m = hm\n",
        "        u = F.linear(x,self.ex)+F.linear(h,self.eh)+F.linear(m,self.em)\n",
        "        new_m = F.linear(m,self.AT) + F.linear(u,self.BT)\n",
        "        new_h = self.act(F.linear(x,self.Wx)+F.linear(h,self.Wh)+F.linear(new_m,self.Wm))\n",
        "\n",
        "        return new_h,new_m\n",
        "\n",
        "\n",
        "class ASSVMU(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, memory_size, theta, name='garbage', discretizer = 'zoh',nonlinearity='sigmoid', \n",
        "                        A_learnable = False, B_learnable = False, activate=False):\n",
        "        super(ASSVMU, self).__init__()\n",
        "        \n",
        "        ### SIZE\n",
        "        self.k = input_size\n",
        "        self.n = hidden_size\n",
        "        self.d = memory_size\n",
        "        \n",
        "\n",
        "        ### PARAMETERS\n",
        "        self.Wx = nn.Parameter(torch.Tensor(self.n,self.k))\n",
        "        self.Wh = nn.Parameter(torch.Tensor(self.n,self.n))\n",
        "        self.Wm = nn.Parameter(torch.Tensor(self.n,self.d))\n",
        "        self.ex = nn.Parameter(torch.Tensor(1,self.k))\n",
        "        self.eh = nn.Parameter(torch.Tensor(1,self.n))\n",
        "        self.em = nn.Parameter(torch.Tensor(1,self.d))\n",
        "\n",
        "        ### A,B MATRIX ----- FIX??\n",
        "        order=self.d\n",
        "        Q = np.arange(order, dtype=np.float64)\n",
        "        R = (2 * Q + 1)[:, None] / theta\n",
        "        j, i = np.meshgrid(Q, Q)\n",
        "        A = np.where(i < j, -1, (-1.0) ** (i - j + 1)) * R\n",
        "        B = (-1.0) ** Q[:, None] * R\n",
        "        C = np.ones((1, order))\n",
        "        D = np.zeros((1,))\n",
        "        self._ss = cont2discrete((A, B, C, D), dt=0.01, method=discretizer)\n",
        "        self._A = self._ss.A\n",
        "        self._B = self._ss.B\n",
        "\n",
        "        ### NON-LINEARITY\n",
        "        self.nl = nonlinearity\n",
        "        if self.nl == 'sigmoid':\n",
        "            self.act = nn.Sigmoid()\n",
        "        elif self.nl == 'tanh':\n",
        "            self.act = nn.Tanh()\n",
        "        else:\n",
        "            self.act = nn.ReLU()\n",
        "\n",
        "        ### NN\n",
        "        self.fc = nn.Linear(self.n,self.n)\n",
        "\n",
        "        if activate:\n",
        "            self.nn_act = self.act\n",
        "        else:\n",
        "            self.nn_act = nn.LeakyReLU(1.0) #Identity Function\n",
        "\n",
        "        ### INITIALIZATION\n",
        "        torch.nn.init.xavier_normal_(self.Wm)    ##### FIGURE THIS OUT!!\n",
        "        torch.nn.init.xavier_normal_(self.Wx)\n",
        "        torch.nn.init.xavier_normal_(self.Wh)\n",
        "        torch.nn.init.zeros_(self.em)\n",
        "        torch.nn.init.uniform_(self.ex, -np.sqrt(3/self.d), np.sqrt(3/self.d))\n",
        "        torch.nn.init.uniform_(self.eh, -np.sqrt(3/self.d), np.sqrt(3/self.d))\n",
        "\n",
        "\n",
        "        #### TRIAL\n",
        "        self.register_buffer('AT', torch.Tensor(self._A))\n",
        "        self.register_buffer('BT', torch.Tensor(self._B))\n",
        "        if A_learnable:\n",
        "            self.AT = nn.Parameter(self.AT)\n",
        "        if B_learnable:\n",
        "            self.BT = nn.Parameter(self.BT)\n",
        "\n",
        "    def forward(self,x,hm):\n",
        "\n",
        "        h,m = hm \n",
        "        u = F.linear(x,self.ex)+F.linear(h,self.eh)+F.linear(m,self.em)\n",
        "        new_m = F.linear(m,self.AT) + F.linear(u,self.BT)\n",
        "        new_h = self.act(F.linear(x,self.Wx)+F.linear(h,self.Wh)+F.linear(new_m,self.Wm))\n",
        "        new_h = self.nn_act(self.fc(new_h))\n",
        "        return new_h,new_m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wikJNQVWSB3J"
      },
      "source": [
        "lmu = LMU(input_size=1,hidden_size=256,memory_size=50,theta=784,matrix_type='pb').to(device)\n",
        "linear = nn.Linear(256,10).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4ebCpCSSMMX"
      },
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lmu.parameters())\n",
        "optimizer_linear = optim.Adam(linear.parameters())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLYj1QklSQrM"
      },
      "source": [
        "def train_model(epoch):\n",
        "\n",
        "\tlmu.train()\n",
        "\tlinear.train()\n",
        "\trunning_loss_train = 0.0\n",
        "\tbatch_size = 1000\n",
        "\n",
        "\ttrain_accuracy = []\n",
        "\n",
        "\tfor batches in range(int(train_batch/batch_size)):\n",
        "\t\t\n",
        "\n",
        "\t\tinputs = images_train[batches*batch_size : (batches+1)*batch_size]\n",
        "\t\tlabels = classes_train[batches*batch_size : (batches+1)*batch_size]\n",
        "\t\t\n",
        "\t\thx = torch.zeros(batch_size, 256).to(device) # (batch, hidden_size)\n",
        "\t\tcx = torch.zeros(batch_size, 50).to(device)\n",
        "\n",
        "\t\tinputs = inputs.permute(1,0,2)\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\toptimizer_linear.zero_grad()\n",
        "\n",
        "\t\tfor i in range(inputs.size()[0]):\n",
        "\t\t\thx,cx = lmu(inputs[i],(hx,cx))\n",
        "\n",
        "\t\toutput = linear(hx)\n",
        "\n",
        "\t\tout = F.log_softmax(output, dim=1)\n",
        "\n",
        "\t\tloss =  F.cross_entropy(out,labels)\n",
        "\n",
        "\n",
        "\t\tloss.backward()\n",
        "\t\toptimizer.step()\n",
        "\t\toptimizer_linear.step()\n",
        "\n",
        "\t\trunning_loss_train += loss.item() * inputs.size(1)\n",
        "\n",
        "\t\t_, predicted = torch.max(out.data, 1) \n",
        "\t\ttrain_accuracy.append((predicted == labels).sum().item() / predicted.size(0))\n",
        "\n",
        "\tepoch_loss_train = running_loss_train / train_batch\n",
        "\t\n",
        "\tprint(\"Train accuracy: \",np.mean(train_accuracy))\n",
        "\tprint(f'Train Loss: {epoch_loss_train:.8f}')\n",
        "\n",
        "\tif(epoch%10==0):\n",
        "\t\ttorch.save(lmu.state_dict(), '/content/drive/Shared drives/CS726/PS_MNIST/bmu_h0_epoch'+str(epoch)+'.pt')\n",
        "\t\ttorch.save(linear.state_dict(), '/content/drive/Shared drives/CS726/PS_MNIST/linear_bmu_h0_epoch'+str(epoch)+'.pt')\n",
        "\n",
        "\t\t\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnk7u2d4SV1u"
      },
      "source": [
        "# Testing Code\t\n",
        "\n",
        "def test_model(epoch):\n",
        "\n",
        "\ttest_accuracy = []\n",
        "\tlmu.eval()\n",
        "\tlinear.eval()\n",
        "\tbatch_size = 1000\n",
        "\trunning_loss_test = 0.0\n",
        "\n",
        "\n",
        "\tfor batches in range(int(test_batch/batch_size)):\n",
        "\n",
        "\t\tinputs = images_test[batches*batch_size : (batches+1)*batch_size]\n",
        "\t\tlabels = classes_test[batches*batch_size : (batches+1)*batch_size]\n",
        "\t\t\n",
        "\t\thx = torch.zeros(batch_size, 256).to(device) # (batch, hidden_size)\n",
        "\t\tcx = torch.zeros(batch_size, 50).to(device)\n",
        "\n",
        "\t\tinputs = inputs.permute(1,0,2)\n",
        "\n",
        "\t\tfor i in range(inputs.size()[0]):\n",
        "\t\t\thx,cx = lmu(inputs[i],(hx,cx))\n",
        "\n",
        "\t\toutput = linear(hx)  \n",
        "\n",
        "\t\tout = F.log_softmax(output, dim=1)\n",
        "\n",
        "\t\tloss =  F.cross_entropy(out,labels)\n",
        "\n",
        "\t\trunning_loss_test += loss.item() * inputs.size(1)\n",
        "\n",
        "\t\t_, predicted = torch.max(out.data, 1) \n",
        "\n",
        "\t\ttest_accuracy.append((predicted == labels).sum().item() / predicted.size(0))\n",
        "\n",
        "\n",
        "\tepoch_loss_test = running_loss_test / test_batch\n",
        "\t\n",
        "\tprint(\"Test accuracy: \",np.mean(test_accuracy))\n",
        "\tprint(f'Test Loss: {epoch_loss_test:.8f}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37NEvAT1SUFH"
      },
      "source": [
        "num_epochs = 256\n",
        "\n",
        "dataiter_train = iter(train_loader)\n",
        "images_train, classes_train = dataiter_train.next()   \n",
        "images_train = images_train.to(device)\n",
        "classes_train = classes_train.to(device) \n",
        "\n",
        "dataiter_test = iter(test_loader)\n",
        "images_test, classes_test = dataiter_test.next()   \n",
        "images_test = images_test.to(device)\n",
        "classes_test = classes_test.to(device) \n",
        "  \n",
        "for epoch in range(num_epochs):\n",
        "  print(f'Epoch {epoch}/{num_epochs}')\n",
        "  print('-' * 10)\n",
        "  train_model(epoch)\n",
        "  test_model(epoch)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}